{"/":{"title":"qProgblog","content":"qProgblog is a blog documenting progress, mostly containing tech workflows and solutions I find useful and I think others would, as well.","lastmodified":"2023-05-05T06:31:15.943194994Z","tags":[]},"/notes/2021-10-21-write-video-chapters":{"title":"Writing Chapters to a Video using ffmpeg and Python","content":"\nAdding *Chapters* to a video file is a great way to navigate through long videos (if there is a comprehensive chapter-structure in the video, that is). One needs a *supported container* and a *supported player*. Most containers support chapters - we're going to use `mkv` since I intend to add chapters to my lecture recordings and I record them in the `mkv` format. **VLC** has support for video chapters.\n\n### Chapters with ffmpeg\n\nWe will use **ffmpeg** to add chapters to our video. The idea is to add chapters to the video metadata, following a certain format. From the [relevant documentation][1]:\n\u003e FFmpeg is able to dump metadata from media files into a simple UTF-8-encoded INI-like text file and then load it back using the metadata muxer/demuxer.\n\nTo see the metadata associated with a video file *input.mkv* we write:\n```shell\nffmpeg -i input.mkv -f ffmetadata metadatafile.txt\n```\nThe metadata is stored in *metadatafile.txt*. For a video with no chapters, it may be as uncomplicated as:\n```shell\n\u003e cat metadatafile.txt\n\n;FFMETADATA1\nencoder=Lavf58.35.101\n```\nTo this file, we need to append chapter data, which has the format\n```\n[CHAPTER]\nTIMEBASE=1/1000\nSTART=0\nEND=60000\ntitle=beginning chapter\n```\nwhere\n  - `TIMEBASE` indicates how many parts a *second* is divided into. *1/1000* means *1000 tsu = 1 sec* (*tsu* is not really a unit XD It stands for *timestamp-unit*, something I'll use throughout the post.)\n  - `START` is the timestamp for start of the chapter.\n  - `END` is the timestamp for end of the the chapter. Typically this is just *1 tsu* behind the start of the next chapter, unless this is the last chapter.\n  - `title` is the name of the chapter of our choice.[^titlenote]\n\nFor each chapter we want to put in, we need to repeat this block.\n\nAfter all that work, to write the metadata back to the video file, we can write:\n```shell\nffmpeg -i input.mkv -i metadatafile.txt -map_metadata 1 -codec copy output.mkv\n```\n\nHowever, it's inconvenient to both write all this stuff repeatedly for each chapter and video *and* convert from our standard sexagesimal representation of video time *hh:mm:ss.uuu* (*uuu* stands for microseconds) to *tsu* units. A good way to scale this issue is to use a scripting language to do all of it for us. For instance, we want to provide the following data to the script:\n```\n5:30 Hello World\n9:11 Bye World\n```\nand expect it to write out the metadata file accordingly.\n\n### The Algorithm:\n  \n  - **Provide chapters in a text file**: Timestamp format is sexagesimal, but flexible. In *hh:mm:ss.uuu*, the *seconds* value must always be given. *hh, mm* and *uuu* are optional and will be interpreted accordingly. This allows for convenient timestamping of any (normal) video duration. \n  - **Get metadata of the video file**\n  - **Get the timestamp of the end of the video file:** This can be done using **ffprobe** ([FFprobeTips][2]):\n  ```shell\n  ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 input.mkv\n  ```\n  `-v error` avoids irrelevant output from **ffprobe**. `-show_entries format=duration` selects only the *duration* of the *container*. `-of default=noprint_wrappers=1:nokey=1` is formatting that ensures that only the *value* of the *duration* is printed, without any extra text. Output is in *seconds*, typically a `float` value.\n  - **Read and process chapters file:** Split lines into (starting) *timestamps* and *chapter name*. Convert sexagesimal format to *tsu* units assuming `TIMEBASE=1/1000`.\n  - **Write out metadata:** Append the form of the block described and repeat for each chapter. Write to video file.\n\n\n\n\n\n\n[^titlenote]: Certain special characters (`=`, `;`, `#`, `\\` and a `newline`) need to preceded with a backslash `\\`. Also, any spaces after `title=` will be part of the chapter name. Hence there's no need to include a space right after `=`.\n\n\n\n\n\n\n\n[1]: \u003chttps://ffmpeg.org/ffmpeg-formats.html#Metadata-1\u003e\n[2]: \u003chttp://trac.ffmpeg.org/wiki/FFprobeTips\u003e","lastmodified":"2023-05-05T06:31:15.943194994Z","tags":["ffmpeg","python","chapters"]},"/notes/2021-10-22-change-pwsh-prompt":{"title":"Customizing the Powershell Prompt","content":"\nInitially I was scanning through Google as usual and found some solutions. The key idea was taken from [this SOF thread][1]. One needs to use *Virtual Terminal Sequences* to do this. \n\n### Using *Virtual Terminal Sequences*:\n\nFrom the Microsoft documentation on [this][2]:\n\n\u003e **Virtual terminal sequences** are control character sequences that can control cursor movement, color/font mode, and other operations when written to the output stream.\n\nWe're interested in **color/font mode** to change the appearance of our prompt. We need a sequence of the format\n```\nESC[\u003cn\u003em\n```\nThere are two parts to this:\n  - We need to the start with the *ASCII ESC character* (hex 0x1B). This can be achieved by writing the expression `$([char]27)` in Powershell.\n  - For `\u003cn\u003e` we insert an appropriate integer code that corresponds to a particular formatting style. The entire list can be found in the same [doc page][3].\n\nWhen we combine the two parts, we write something like:\n```powershell\n$([char]27)[36m\n```\nwhich applies *non-bold/bright \u003cspan style=\"color:rgb(88,209,235)\"\u003e**cyan**\u003c/span\u003e to foreground*. The text that follows will acquire this style. To negate all styles we use `ESC[0m`.\n\n#### Custom colours:\n\nWith `ESC[38;2;\u003cr\u003e;\u003cg\u003e;\u003cb\u003em`(`ESC[48;...`) one can use any *(r, g, b)* value for the text foreground (background). For instance, *(250, 128, 114)* is the \u003cspan style=\"color:rgb(250,128,114)\"\u003e**salmon**\u003c/span\u003e colour.\n\n### Changing the prompt permanently\n\nWe modify the Powershell *profile* file to make changes permanent. ([Creating profiles][4]) We add the following lines:\n```powershell\n$ESC = [char]27\nfunction prompt {\n    $(if (Test-Path variable:/PSDebugContext) { '[DBG]: ' }\n      else { '' }) + \"$ESC[38;2;250;128;114mPS@$ESC[38;2;127;255;255m$ESC[4m\" + $(Get-Location) + \"$ESC[24m\" +\n        $(if ($NestedPromptLevel -ge 1) { '\u003e\u003e' }) + \"\u003e $ESC[0m\"\n}\n```\nwhere\n  - We have stored the *ESC* character in a variable to ease our life.\n  - The `prompt()` function is used to modify the prompt. The code within the `prompt()` function has been obtained from the [doc][5] on Powershell prompt.\n  - The *built-in prompt* has been modified[^wrongsol] by inserting sequences at appropriate places. Currently, it should look like this:\n\n  ![](/res/pwsh_prompt_211022/newprompt.png)\n\nFor changes to take effect immediately, source the profile using `. $profile`.\n\n\n\n\n\n\n[^wrongsol]: The original SOF solution (and many other places) give this solution:\n    ```powershell\n    function prompt  \n    {  \n        \"$ESC[93mPS $ESC[36m$($executionContext.SessionState.Path.CurrentLocation)$('\u003e' * ($nestedPromptLevel + 1)) $ESC[0m\"  \n    }\n    ```\n    but `$('\u003e' * ($nestedPromptLevel + 1))` causes issues. More specifically, the character **m** appeared automatically after the prompt when I was typing a period `.` which is undesirable behaviour. \u003cspan style=\"color:red\"\u003e*TO BE INVESTIGATED.*\u003c/span\u003e\n\n\n\n\n\n\n[1]: \u003chttps://superuser.com/a/1259916/1171201\u003e\n[2]: \u003chttps://docs.microsoft.com/en-us/windows/console/console-virtual-terminal-sequences\u003e\n[3]: \u003chttps://docs.microsoft.com/en-us/windows/console/console-virtual-terminal-sequences#text-formatting\u003e\n[4]: \u003c{% post_url /pwsh_profile_211022/2021-10-22-pwsh-profile %}\u003e\n[5]: \u003chttps://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.core/about/about_prompts?view=powershell-7.1#built-in-prompt\u003e","lastmodified":"2023-05-05T06:31:15.943194994Z","tags":["windows","powershell","prompt"]},"/notes/2021-10-22-change-term-prompt-omp":{"title":"Customizing the Terminal Prompt with oh-my-posh","content":"\nThe module **oh-my-posh** is the Windows equivalent of **oh-my-zsh** for Linux. It can help create pretty prompts which may provide visual aids with *git* (among other things?[^obs1]). I stumbled upon this idea on [this blog][1], but really, it's a very commonly used module. I'm going to use the **Windows Terminal**.\n\n### Installing a NerdFont\n\n**oh-my-posh** uses glyphs that are not present in standard fonts. To get them, we need to install one of many *NerdFonts* from the [website][2]. **Windows Terminal** by default uses *Cascadia* fonts.  I prefer to use *Fira Code* instead. So we can just search for *Fira Code* in the website (or download any font - doesn't really matter). The fonts will be downloaded in a *zip* format.\n\n*Install* and check the name of the font in the font file. In my case, it is \"FiraCode Nerd Font\". Now we can go to Terminal settings by pressing `Ctrl+Shift+,` which will open the settings in JSON format, and add this to the `\"profiles\": \"defaults\":` key:\n```\n\"font\": \n            {\n                \"face\": \"FiraCode Nerd Font\"\n            }\n```\nThis is the place where we can adjust the size and style of the font if desired, e.g `\"size\": 10`. Save and Terminal refreshes, now using the installed NerdFont.\n\n### Shell-independent installation in Windows\n\nFrom [this guide][3]. First, we need to install **oh-my-posh**. We can do this using **winget**, the package manager CLI in Windows:\n```\nwinget install JanDeDobbeleer.OhMyPosh\n```\nNow we will have the `oh-my-posh.exe` application which we can use to customize our prompt. For WSL, this will be `oh-my-posh-wsl` instead. Themes are present at the location *~\\AppData\\Local\\Programs\\oh-my-posh\\themes*. We can list all the theme names:\n```\nls ~\\AppData\\Local\\Programs\\oh-my-posh\\themes\\\n```\nwhich are just JSON files with the name format **.omp.json*. To actually *view* the themes in action, however, we can run the following command:\n```powershell\nGet-ChildItem -Path \"~\\AppData\\Local\\Programs\\oh-my-posh\\themes\\*\" -Include '*.omp.json' | Sort-Object Name | ForEach-Object -Process {\n    $esc = [char]27\n    Write-Host \"\"\n    Write-Host \"$esc[1m$($_.BaseName)$esc[0m\"\n    Write-Host \"\"\n    oh-my-posh --config $($_.FullName) --pwd $PWD\n    Write-Host \"\"\n}\n```\nwhich basically loops through all the JSON files in the folder and prints a custom prompt for each. To actually change the prompt, we can run\n```powershell\noh-my-posh --init --shell pwsh --config ~/AppData/Local/Programs/oh-my-posh/themes/jandedobbeleer.omp.json | Invoke-Expression\n```\nin Powershell, or \n```bash\neval \"$(oh-my-posh-wsl --init --shell bash --config $USERPROFILE/AppData/Local/Programs/oh-my-posh/themes/jandedobbeleer.omp.json)\"\n```\non *bash* in WSL.[^envvarnote]\n\nTo make changes permanent, we need to add this command to the profile of the respective shells (*$profile* for Powershell and *.bashrc* for bash).\n\n#### Remarks\n\nEven though it seems like a PITA[^pita] to write such a complicated path again and again (especially in WSL), once we've written it, all we have to do is modify the name of the theme (here `jandedobbeleer`) and not touch the path at all. However, if we are to [modify these themes][4] to our liking, it is wise to copy the JSON files to another location and make necessary changes, and *then* make the *shell profile* point to that location.\n\n### Only for Powershell\n\nTo start with, we run:\n```powershell\nInstall-Module oh-my-posh -Scope CurrentUser\n```\nin Powershell. This installs the **oh-my-posh** module for the current user (admin privileges not required?).\n\n\n\n\n\n\n[^obs1]: For instance, it marks the root folder of this Jekyll website with a little ruby icon (Jekyll uses Ruby and the root folder has a *Gemfile*) or a Python symbol when python files are present.\n\n[^envvarnote]: The environment variable `$USERPROFILE` does not exist by default. It has to be *forwarded* from Windows to WSL via the `WSLENV` variable:\n    ```powershell\n    setx WSLENV USERPROFILE/up\n    ```\n    and after a session restart, the Windows environment variable `%USERPROFILE%` containing the path to the user profile is available at `$USERPROFILE` in WSL (translated to a Linux-style path, the `/p` switch does this). ([Source][5])\n\n[^pita]: Pain-In-The-Ass.\n\n\n\n\n\n\n\n[1]: \u003chttps://zimmergren.net/making-windows-terminal-look-awesome-with-oh-my-posh/\u003e\n[2]: \u003chttps://www.nerdfonts.com/font-downloads\u003e\n[3]: \u003chttps://ohmyposh.dev/docs/windows\u003e\n[4]: \u003chttps://ohmyposh.dev/docs/configure\u003e\n[5]: \u003chttps://superuser.com/a/1546688/1171201\u003e","lastmodified":"2023-05-05T06:31:15.943194994Z","tags":["windows","powershell","prompt","oh-my-posh"]},"/notes/2021-10-22-pwsh-profile":{"title":"Adding a Powershell Profile","content":"\nThe Powershell profile is equivalent to the *~/.bashrc* file for *bash* in Linux. It helps load a desired configuration when a Powershell instance is run.\n\nTo test if there is a profile:\n```powershell\nTest-Path $profile\n```\nThe variable `$profile` refers to the profile. If absent, this returns `False`. If `False`, create one:\n```powershell\nNew-Item -path $profile -type file -force\n```\nA typical (user) profile path looks like:\n```powershell\n$home\\Documents\\WindowsPowerShell\\Microsoft.PowerShell_profile.ps1\n```\nwhere for me, `$home = C:\\Users\\Ayon\\` - *Ayon* is the *username*.\n\nOnce created, we can use an editor to edit the file. I use *Sublime Text* (cli: *subl*) for the purpose:\n```powershell\nsubl $profile\n```\n\n### Script running permissions:\n\nRunning scripts on Powershell might be disabled by default. From [this thread][1], we can use Powershell as Admin (*Win+X-\u003eA*) to change the *execution policy* of scripts:\n```powershell\nSet-ExecutionPolicy RemoteSigned\n```\nThis worked for my use case. The `Unrestricted` flag can be used instead, but I haven't researched about when I should do so. \u003cspan style=\"color:red\"\u003e*TO BE INVESTIGATED.*\u003c/span\u003e\n\n\n\n\n\n[1]: \u003chttps://answers.microsoft.com/en-us/windows/forum/all/whats-wrong-with-my-windows-powershell/f05e72f2-a429-4ee0-81fb-910c8c8a1306\u003e\n","lastmodified":"2023-05-05T06:31:15.943194994Z","tags":["windows","powershell","profile"]},"/notes/2021-10-26-jekyll-setup-wsl":{"title":"Setting up Jekyll on WSL","content":"[//]: # (The body)\n\nThis guide is mainly an accumulation of information from two sources, both from the *Jekyll Docs*:\n  - [Windows Installation][1]\n  - [Troubleshooting][2]\n\n### Installation:\n\nWe plan to install Jekyll[^vernote] on **Ubuntu 20.04 on WSL**. For this we have to install **Ruby**. The Ruby *gems*, however, we want to install only for the user (instead of a system-wide installation). For this purpose we edit the *~/.bashrc* file and add the following:\n```shell\n# Ruby exports\n\nexport GEM_HOME=$HOME/gems\nexport PATH=$HOME/gems/bin:$PATH\n```\nwhich basically sets the path where the *gems* will be installed. We need to source the *~/.bashrc* file now...\n```shell\nsource ~/.bashrc\n```\n\nNow we start with the **Ruby** installation. We install this from the **BrightBox** PPA (Personal Package Archive):\n\u003e which hosts optimized versions of Ruby for Ubuntu. [(ref)][1]\n\n```shell\nsudo apt-add-repository ppa:brightbox/ruby-ng\nsudo apt-get update\nsudo apt-get install ruby2.5 ruby2.5-dev build-essential dh-autoreconf\n```\nUpdate our gems:[^failnote1]\n```shell\ngem update\n```\nand finally install **Jekyll** and **Bundler**[^failnote2]:\n```shell\ngem install jekyll bundler\n```\nAnd then we can check the version using `jekyll -v`.\n\n### New blog setup:\n\nA blog can be quickly set up with\n```shell\njekyll new sitename\n```\nwhich will create a folder named *sitename* with all the relevant files. After that, we can `cd sitename` and start a server at that location:\n```shell\nbundle exec jekyll serve --force-polling\n```\n*(As of 26-Oct-2021)* Without the `--force-polling` option, changes made to files in the site are not reflected upon reload in the website. The command itself displays this warning:\n```\nAuto-regeneration may not work on some Windows versions.\nPlease see: https://github.com/Microsoft/BashOnWindows/issues/216\nIf it does not work, please upgrade Bash on Windows or run Jekyll with --no-watch.\n```\nOne can also add the option `--livereload` to have the website reload automatically when the files are changed. Solution from issue [#216][3] in the *WSL repo*.\n\n\n\n\n\n\n\n[//]: # (Footnotes, if any)\n\n[^vernote]: We use a fairly old version of **Ruby** (2.5.8p224) here, following the tutorial. It's not necessary to do this, but various gems have to have versions whicha re consistent with each other for the whole thing to work. So this is a safe bet.\n[^failnote1]: In my case, a few gems failed to update properly.\n[^failnote2]: By default, this fails (version conflict between **RubyGems** and **Ruby**?).\n    ```shell\n    Fetching: public_suffix-4.0.6.gem (100%)\nERROR:  While executing gem ... (ArgumentError)\n    wrong number of arguments (given 4, expected 1)\n    ```\n    however, `gem uninstall psych` fixes the issue and installation completes successfully ([source][4]). \u003cspan style=\"color:red\"\u003e*TO BE INVESTIGATED.*\u003c/span\u003e\n\n\n\n\n\n[//]: # (Links, if any)\n\n[1]: \u003chttps://jekyllrb.com/docs/installation/windows/\u003e\n[2]: \u003chttps://jekyllrb.com/docs/troubleshooting/#no-sudo\u003e\n[3]: \u003chttps://github.com/microsoft/WSL/issues/216#issuecomment-716047269\u003e\n[4]: \u003chttps://stackguides.com/questions/68899508/gem-install-wrong-number-of-arguments-given-4-expected-1\u003e","lastmodified":"2023-05-05T06:31:15.943194994Z","tags":["jekyll","wsl"]},"/notes/2021-11-09-min-adb-sw-removal":{"title":"Installing Minimal ADB and Removing Bloatware","content":"[//]: # (The body)\n\nThe **Android Debug Bridge (ADB)** provides an interface between an Android device and a PC. The connection can be made using USB or Wi-Fi (if on the same network). From [this XDA guide][1]:\n\nThe internal structure of the Android Debug Bridge (ADB) is based on the classic client-server architecture. There are three components that make up the entire process.\n\n  - The client, i.e. the PC you have connected to your Android device. We are sending commands to our device from the computer.\n  - A daemon (`adbd`), which runs commands on a device. The daemon runs as a background process on each device.\n  - A server, which manages communication between the client and the daemon and runs as a background process on the PC.\n\nTypically, to install **ADB** one must install the **Android SDK**, which is *\u003e400 MB* in size. It is sufficient to install the **Android SDK Platform-Tools**, but that's *\u003e90 MB*. For someone not looking forward to full-scale Android development, this seems like an overkill (it is). This is where the **Minimal ADB** comes in. Found in [this XDA thread][2][^vernote], it provides all the necessary files in a neat package of *~3 MB*. I use the portable version, as I don't really need to install the program.\n\n### Working with adb\n\nTo start working with **adb** we need to go to *Developer Options*[^dops] in Settings and enable USB debugging. Now, we can fire up a shell and type\n```shell\nadb devices\n```\n(or `./adb \u003ccommands\u003e` in the folder where **adb** is, if not in *PATH*.) which shows the devices connected via **ADB**. Initially, there will be none. On a fresh start, this will start the daemon:\n```\n* daemon not running; starting now at tcp:5037\n* daemon started successfully\nList of devices attached\n\n```\nNow if we connect our phone via USB to the computer, we would prompted for permission to debug *on our phone* (if the adb server is running - if not, run `adb devices`). If allowed, our device will show up with a serial number on the list.\n\n#### Connecting via Wi-Fi\n\nIt is also possible to connect to the device via Wi-Fi. \n\n  1. **On Android 10 and lower**, the initial setup requires a USB connection. According to [this guide][5],\n      - We must first connect the device via USB.\n      - We set the device to listen on a port (here, *5555*) for a TCP/IP connection:\n\n        ```shell\n        adb tcpip 5555\n        ```\n        and disconnect the USB cable.\n      - We need to find the IP address of the phone on the network. This can be usually found at *About phone \u003e Status info \u003e IP address*.\n      - We can now run\n\n        ```shell\n        adb connect ip_addr:5555\n        ```\n        to connect to the device. If successful, `adb devices` will list the device.[^wifidbg] To connect to this device anytime in future, we just need to run the `connect` command with the `ip_addr` *at that time* at port *5555*.\n\n  2. **On Android 11 (and higher?)**, no USB connection is required. Following [this guide][6],\n      - We must turn on *Wireless Debugging* in *Developer Settings* on our phone. On opening the *Wireless Debugging* settings, we will have the option to *\"Pair device with pairing code\"*, which will show a 6-digit pairing code alongwith the IP address of the phone and a port to connect to.\n      - Run\n      ```\n      adb pair ip_addr:port\n      ```\n      using values from last step. We will be asked for the pairing code next. Once entered, pairing should succeed and our phone should list the name of the PC under *Paired devices*.\n      - Now we connect:\n      ```\n      adb connect ip_addr:port\n      ```\n      *This port will in general NOT be same as the previous one!* This port number is listed under the *Wireless Debugging* settings. This completes the setup. Also, in this case, the port to connect to keeps changing - so when we need to connect to the device at a later time, we need to input the correct port number as well.\n\n**Note 1:** If we want to disconnect, we can simply run `adb kill-server`. All devices will be disconnected. \n\n\n**Note 2:** If we want a detailed list of connected devices, we can run\n```shell\nadb devices -l\n```\nwhich displays more info like the model number and device name.\n\nWe can access the adb shell by typing `adb shell`. This will work only if a device is connected, as the shell opens at the device root `/`.\n\n### Uninstalling packages\n\n`pm` is the package manager of adb. In the adb shell, we can write\n```shell\nm30s:/ $ pm list packages\n```\n(the device name is displayed first: here `m30s`)\nto list all installed packages (the list will be long!). A few Linux commands also work in the shell, hence we could, say, grab only the apps with the word 'samsung' in it:\n```shell\nm30s:/ $ pm list packages | grep 'samsung'\n```\nFinally, we can use\n```shell\nm30s:/ $ pm uninstall –k --user 0 \u003cpackage-name\u003e\n```\nto uninstall packages.[^unstnote] The `-k` switch keeps data and user cache. The `--user 0` option uninstalls only for the current user (of the device).\n\n\n\n\n\n\n[//]: # (Footnotes, if any)\n\n[^vernote]: This thread was last updated on *02-09-2018* and the ADB version packaged is old (v1.0.39). Here's a [thread][3] that provides **Tiny ADB and Fastboot** was updated on *August 2021* and uses v1.0.41 (size: *~7 MB*).\n[^dops]: One needs to reveal the *Developer Settings* by tapping on *Build number* in phone software information 7 times quickly in succession.\n[^wifidbg]: Interestingly, this method does not require turning on *Wireless debugging* in the phone.\n[^unstnote]: Without rooting a device, we technically cannot uninstall system packages using adb. This is because one does not have write permissions on the */system* partition. ([More on this][4]) We hide them from the user so these apps do not run anymore. They're still on device storage.\n\n\n\n\n\n[//]: # (Links, if any)\n\n[1]: \u003chttps://www.xda-developers.com/install-adb-windows-macos-linux/\u003e\n[2]: \u003chttps://forum.xda-developers.com/t/tool-minimal-adb-and-fastboot-2-9-18.2317790/\u003e\n[3]: \u003chttps://forum.xda-developers.com/t/tool-windows-tiny-adb-fastboot-august-2021.3944288/\u003e\n[4]: \u003chttps://gitlab.com/W1nst0n/universal-android-debloater/-/wikis/FAQ\u003e\n[5]: \u003chttps://developer.android.com/studio/command-line/adb/?gclid=CjwKCAjw2dD7BRASEiwAWCtCbxKzwu63T-HpLaIp8ASO1aNA6aRl7_8Wvc2LqCvf3BI3umOlQQaOtBoCQrEQAvD_BwE\u0026gclsrc=aw.ds#wireless\u003e\n[6]: \u003chttps://developer.android.com/studio/run/device#wireless\u003e","lastmodified":"2023-05-05T06:31:15.943194994Z","tags":["adb","android"]},"/notes/2021-12-02-wsl-fonts":{"title":"Use Windows Fonts in WSL","content":"[//]: # (The body)\n\nOut of the box, it seems like **WSL** comes with only a limited set of fonts. While for a CLI environment this might (?) be adequate, when we start using GUI apps in WSL (which it now supports via **WSLg**), font support would really start to matter. When I was using web-browsers like **qutebrowser** and **surf** on WSL, I found that most glyphs were not rendered. Furthermore, while using the **gnome-tweaks** tool which lists the fonts available, the list was very short. The available fonts can also be viewed with\n```shell\nfc-list\n```\nwhich is basically the **font-config** utility. Our plan is to use fonts installed in Windows instead of installing any more, following [this guide][1].\n\nWindows fonts reside primarily in two locations:\n  - Default fonts in *C:/Windows/Fonts* directory (if installed for all users)\n  - User-installed fonts in *%USERPROFILE%/AppData/Local/Microsoft/Windows/Fonts* directory (if installed per-user)\n\nWe need to refer to these two locations. For that, we go to\n```shell\ncd /etc/fonts\n```\nand create a new configuration file *local.conf* with admin privileges:\n```shell\nsudo vi local.conf\n```\nand write the following\n```xml {title=\"/etc/fonts/local.conf\"}\n\u003c?xml version=\"1.0\"?\u003e\n\u003c!DOCTYPE fontconfig SYSTEM \"fonts.dtd\"\u003e\n\u003cfontconfig\u003e\n        \u003cdir\u003e/mnt/c/Windows/Fonts\u003c/dir\u003e\n        \u003cdir\u003e/mnt/c/Users/user-name/AppData/Local/Microsoft/Windows/Fonts\u003c/dir\u003e\n\u003c/fontconfig\u003e\n```\nwhere we have translated the paths to Linux-style paths. The second directory addition is a little iffy because it depends on the username (\"user-name\"). We can skip the second addition if one installs all fonts for all users: *Right-click on font \u003e Install for all users*.\n\nNext we can refresh the font-cache:\n```\nfc-cache -fv\n```\nwhere `-f` forces scan of directories where font-cache is present, `-v` displays verbose output.\n\n\n\n\n\n[//]: # (Footnotes, if any)\n\n[^fn]: Footnote\n\n\n\n\n\n[//]: # (Links, if any)\n\n[1]: \u003chttps://www.linuxtut.com/en/6ea7665529b022eb5f45/\u003e","lastmodified":"2023-05-05T06:31:15.943194994Z","tags":["wsl","fonts"]},"/notes/2022-01-13-cmdrun-winstoreapp":{"title":"Run Windows Store App from command line","content":"[//]: # (The body)\n\nThe procedure to launch Windows Store apps manually seems to be convoluted, as there are a host of permission issues associated with it. Windows Store apps are usually stored in the folder *C:\\Program Files\\WindowsApps*. The folder is hidden and permissions are restricted. Apps within this folder cannot be run manually (atleast in my experience?). \n\nThe method outlined here helps us launch such an application manually from the command line, which might be handy. We follow [this guide][1] loosely.\n\nThe command that achieves it has the format\n```\nexplorer shell:appsfolder\\\u003cPackageFamilyName\u003e!\u003cApplicationID\u003e\n```\nTime to explain!\n\nThe *shell:appsfolder* location points to all the installed applications on the system. Indeed, if we type this out in the File Explorer address bar or in the Windows Run dialog, we're taken to the folder.[^accessmethod] Now we need to find the *PackageFamilyName* and *ApplicationID* of the Windows Store app of interest. \n\nTo do so, we create a shortcut (on the Desktop) of the app of interest by right-clicking on it in the *shell:appsfolder*. Once, the shortcut is created, we open its **Properties** and under the **Shortcut** tab, we can see the **Target** field which lists exactly the `\u003cPackageFamilyName\u003e!\u003cApplicationID\u003e` format, but this being an [advertised shortcut][2], the field will be greyed out and since the entry is long, it might not be possible to read all of it. If one can, however - our task's accomplished - just put it in the format and the application runs! Otherwise, read on.\n\nWe run a powershell instance and run the following command:\n```powershell\nGet-AppxPackage -Name \"\u003capp-name-wildcard\u003e\"\n```\nwhere `\u003capp-name-wildcard\u003e` is a wildcard string that is related to our application of interest. Basically, we use a part of the application name (which we of course, know) along with wildcard characters to find the relevent app entry using `Get-AppxPackage`. For example, this displays the entry of the **Microsoft Photos** app (bundled by default):\n```powershell\nGet-AppxPackage -Name \"*Photo*\"\n\n\nName              : Microsoft.Windows.Photos\nPublisher         : CN=Microsoft Corporation, O=Microsoft Corporation, L=Redmond, S=Washington, C=US\nArchitecture      : X64\nResourceId        :\nVersion           : 2021.21110.8005.0\nPackageFullName   : Microsoft.Windows.Photos_2021.21110.8005.0_x64__8wekyb3d8bbwe\nInstallLocation   : C:\\Program Files\\WindowsApps\\Microsoft.Windows.Photos_2021.21110.8005.0_x64__8wekyb3d8bbwe\nIsFramework       : False\nPackageFamilyName : Microsoft.Windows.Photos_8wekyb3d8bbwe\nPublisherId       : 8wekyb3d8bbwe\nIsResourcePackage : False\nIsBundle          : False\nIsDevelopmentMode : False\nNonRemovable      : False\nDependencies      : {Microsoft.Photos.MediaEngineDLC_1.0.0.0_x64__8wekyb3d8bbwe,\n                    Microsoft.UI.Xaml.2.6_2.62112.3002.0_x64__8wekyb3d8bbwe,\n                    Microsoft.NET.Native.Framework.2.2_2.2.29512.0_x64__8wekyb3d8bbwe,\n                    Microsoft.NET.Native.Runtime.2.2_2.2.28604.0_x64__8wekyb3d8bbwe...}\nIsPartiallyStaged : False\nSignatureKind     : Store\nStatus            : Ok\n```\nThis method displays both the *PackageFamilyName* (*Microsoft.Windows.Photos_8wekyb3d8bbwe* in this case) and the location of the executable (*C:\\Program Files\\WindowsApps\\Microsoft.Windows.Photos_2021.21110.8005.0_x64__8wekyb3d8bbwe*). A less hit-and-miss method would be to use keywords we found in the target field of the app shortcut (preferably, the beginning of the string, which we can always see) and use the `Where-Object` cmdlet to filter results using the *PackageFamilyName* itself[^shortcut]... like so:\n```powershell\nGet-AppxPackage | Where-Object {$_ -like \"*Photo*\"}\n```\nwith that out of the way, we can now go to the folder containing the app and find the *AppxManifest.xml* file there. In this file, we need to find the *ApplicationID*.[^appid] For **Microsoft Photos**, for instance:\n```xml\n\u003cApplication Id=\"App\" Executable=\"Microsoft.Photos.exe\" EntryPoint=\"AppStubCS.Windows.App\" ResourceGroup=\"AppGroup\"\u003e\n```\nThe *ApplicationID* is just \"App\" in this case. So, the command to launch **Microsoft Photos** from the command line then becomes:\n```powershell\nexplorer shell:appsfolder\\Microsoft.Windows.Photos_8wekyb3d8bbwe!App\n```\n\n\n\n\n\n\n\n[//]: # (Footnotes, if any)\n\n[^accessmethod]: I personally use **Microsoft Powertoys** for the same - `\u003e shell:appsfolder` does the trick.\n[^shortcut]: The first method, if it works reliably, then creating the shortcut or going to *shell:appsfolder* is redundant.\n[^appid]: A simple document search should do. We should search for the *Executable=* property of the application, as one application package may contain more than one application. \n\n\n\n\n\n[//]: # (Links, if any)\n\n[1]: \u003chttps://www.tenforums.com/software-apps/57000-method-open-any-windows-10-apps-command-line.html\u003e\n[2]: \u003chttps://stackoverflow.com/a/1270833/12983399\u003e","lastmodified":"2023-05-05T06:31:15.943194994Z","tags":["windows-store","commandline"]},"/notes/2022-03-20-wsl-with-lxrunoffline":{"title":"Managing WSL distros with LxRunOffline","content":"[//]: # (The body)\n\n**LxRunOffline** is a tool for managing WSL distributions.\n\nCan be installed using **chocolatey**:\n```powershell\nchoco install lxrunoffline\n```\n### Installing distros\n\nDetailed information in the [github repo wiki][1]. Installation of a distro can be done as follows:\n```powershell\nLxRunOffline i -n {custom-distro-name} -d {install-location} -f {name-of-tar-file}\n```\nwhere the tar file has been downloaded from \u003chttps://lxrunoffline.apphb.com/download/{distro}/{version}\u003e for the required distribution *or* is a previously exported distro (using `wsl --export` or LxRunOffline itself).\n\nThe installed distros can be viewed with `LxRunOffline l`. For detailed summary of an installed distro:\n```powershell\nLxRunOffline sm -n {custom-distro-name}\n```\n\nUnfortunately, **LxRunOffline** installs distros using WSL1. If one has to upgrade to WSL2, one must run\n```powershell\nwsl --set-version {custom-distro-name} 2\n```\nThis conversion, however, may fail, or take an insanely long time depending on the size of the distro and other *undocumented* reasons (?) as detailed in [github:microsoft/WSL:issue#5344][2] or [github:microsoft/WSL:issue#4626][3].\n\nFor a fresh install this should work. (?) Of course, there is a lot of guessing here as I don't know the exact reasons. For me, importing an old distribution with **wsl** failed - and after installing it with **LxRunOffline**, **wsl** still failed to convert it to version 2, stating\n```\nConversion in progress, this may take a few minutes.\nImporting the distribution failed.\n```\nafter some time. \u003cspan style=\"color:red\"\u003e*TO BE INVESTIGATED.*\u003c/span\u003e\n\n### Setting the user\n\nIf installed this way, the distro will probably default to the `root` user. To avoid this, we can create a new user from `root`. First, we list the available users. This is stored in */etc/passwd*:\n```bash\n$ cat /etc/passwd\n```\nor to just get the usernames and the user ids:\n```bash\n$ awk -F: '{print $1,$3}' /etc/passwd\n```\nwhere we specify the separator `:` using `-F` and print only the first entry `$1` (which is the username) from the file. As we can see from the first output, the `root` user has id 0. The default login user usually has id 1000. There are many users with non-login shells as well, not of interest. \n\nNow to create an user:\n```bash\n$ adduser {user-name}\n```\nafter which we will be prompted to enter the password and user information. Now we can re-list the users to check the user id (this should be 1000 if there weren't any users already).\n\nFinally, we shutdown the wsl distro and set the default user[^setdefuser]\n```powershell\nLxRunOffline su -n {custom-distro-name} -v {user-id}\n```\nwhere `su` stands for *set user*. The next time we open the distro, we will login as this user by default.\n\n\n\n\n\n\n[//]: # (Footnotes, if any)\n\n[^setdefuser]: This is only for imported/custom-installed distros. For a distro installed using the default mode `wsl --install` this can be done using \n    ```powershell\n    {distro-name} config --default-user {user-name}\n    ```\n    from Powershell/cmd.\n\n\n\n\n[//]: # (Links, if any)\n\n[1]: \u003chttps://github.com/DDoSolitary/LxRunOffline/wiki\u003e\n[2]: \u003chttps://github.com/microsoft/WSL/issues/5344\u003e\n[3]: \u003chttps://github.com/microsoft/WSL/issues/4626\u003e","lastmodified":"2023-05-05T06:31:15.943194994Z","tags":["wsl","lxrunoffline"]},"/notes/2022-03-26-pyenv-virtualenv":{"title":"Python virtual environments with pyenv","content":"[//]: # (The body)\n\nVirtual environments isolate a set of executables, libraries and related files from another such set. From the **python** [docs][1]:\n\u003e A virtual environment is a Python environment such that the Python interpreter, libraries and scripts installed into it are isolated from those installed in other virtual environments, and (by default) any libraries installed in a “system” Python, i.e., one which is installed as part of your operating system.\n\nThere are many options to do this: **venv** (comes installed by default with Python 3.3+), **virtualenv**, **conda**, **poetry** and so on... For people like us who use these languages mostly for scientific work, **conda** is a great option (and for other applications too - it handles dependency management well and has its own package manager `conda`), but it irks me to great measure because to install conda you'd have to install a **python** version (the *base* version of conda) again (?!) and the install size, even for [**miniconda**][2], is ~400MB. It is however a good option if that's the *first python installation one starts with* - I happened to have a working python installation (v3.9.7 on Ubuntu 21.10 on WSL) with many packages and I was unwilling to get rid of it and consequently break many applications.\n\nAlso, many applications demand a different python version altogether. If one does not use **conda**, separate python versions must be installed which can also break functionality if the path to the appropriate executable is not set in `PATH` and scripts do not properly select the right version. So this demands proper management. This is what we achieve with [**pyenv**][3].\n\n**pyenv** helps manage various python installations on the system easily and also provides the plugin [**pyenv-virtualenv**][pyvnv] (installed separately, based on **venv**/**virtualenv**: [more on this][pyvnv-method]). \n\n### Installation\n\nTo start with, we configure a [proper build environment][buildenv] for building Python distributions with **pyenv** on-the-fly:\n```bash\nsudo apt-get update; \\\nsudo apt-get install make build-essential libssl-dev zlib1g-dev \\\nlibbz2-dev libreadline-dev libsqlite3-dev wget curl llvm \\\nlibncursesw5-dev xz-utils tk-dev libxml2-dev libxmlsec1-dev libffi-dev liblzma-dev\n```\nSome of these packages would probably already be installed, but be prepared to install a bulk of packages. For me the download size was ~100MB and installation size ~500MB. [^sizeissue]\n\nOnce this is done, we install **pyenv** via a Github checkout (of course, `git` needs to be installed). To do so, we first clone the repo:\n```bash\n git clone https://github.com/pyenv/pyenv.git ~/.pyenv\n```\nwhere the location has been set as *~/.pyenv/*. This can be changed. Next, we optionally *try* to compile a *dynamic Bash extension* (without this step, **pyenv** works just fine, this should just speed up **pyenv**):\n```bash\n cd ~/.pyenv \u0026\u0026 src/configure \u0026\u0026 make -C src\n```\nNext, we configure the shell's environment to work with **pyenv**. For bash on Ubuntu with a *.profile* file that sources *.bashrc*, \n```bash\nsed -Ei -e '/^([^#]|$)/ {a \\\nexport PYENV_ROOT=\"$HOME/.pyenv\"\na \\\nexport PATH=\"$PYENV_ROOT/bin:$PATH\"\na \\\n' -e ':a' -e '$!{n;ba};}' ~/.profile\n```\nThis puts the two `export` lines at the beginning (which is why we do all the gymnastics with `sed`) of *.profile* to \n  - Create the variable *$PYENV_ROOT* which stores the path to the folder we cloned the repo to, and\n  - Add this variable to (the beginning of) *$PATH*.\n```bash\necho 'eval \"$(pyenv init --path)\"' \u003e\u003e~/.profile\n```\nThis puts the pyenv *shims* into *$PATH*. The *shims* redirect calls to the python executable to the right one. Details on the working [here][shimswork].\n```bash\necho 'eval \"$(pyenv init -)\"' \u003e\u003e ~/.bashrc\n```\nand this modifies *.bashrc*. For other setups, see [here][setup].\n\nFinally, we restart the shell - and we're done installing pyenv!\n\nNext, we install **pyenv-virtualenv**. This simply requires checking out the repo to the *.pyenv/plugins/* directory:\n```bash\ngit clone https://github.com/pyenv/pyenv-virtualenv.git $(pyenv root)/plugins/pyenv-virtualenv\n```\nand we then run\n```bash\nexec \u003cshell\u003e\n```\n(in our case, `\u003cshell\u003e` is just `bash`) to restart the shell.\n\nIf installed with this method, upgrading is super simple - we just go the *.pyenv* directory and pull from the repo.\n```bash\ncd $(pyenv root)\ngit pull\n```\nand a similar procedure follows for **pyenv-virtualenv**.\n\n### Usage\n\nWhen using **pyenv**, we have a *system* version of python that is present by default (python was installed by default, of course). We can install more versions by running\n```bash\npyenv install \u003cversion\u003e\n```\nwhere we `\u003cversion\u003e` may be replaced by `3.8.1`, for instance. We can list all available versions by typing\n```bash\npyenv install --list\n```\nand choose the appropriate one. After installation, this goes under *.pyenv/versions/{version}/* and all packages/virtual-environments concerning this version go under this directory. We can list the currently installed versions by\n```bash\npyenv versions\n```\nThe currently active version is marked by an asterisk (\\*). This can also be checked by running `pyenv version` instead. The output of the command will depend upon the current session or the current location. This is how **pyenv** chooses the python version (from the docs):\n\u003e  1. The *PYENV_VERSION* environment variable (if specified). You can use the `pyenv shell` command to set this environment variable in your current shell session.\n\u003e\n\u003e  2. The application-specific *.python-version* file in the current directory (if present). You can modify the current directory's *.python-version* file with the `pyenv local` command.\n\u003e\n\u003e  3. The first *.python-version* file found (if any) by searching each parent directory, until reaching the root of your filesystem.\n\u003e\n\u003e  4. The global *$(pyenv root)/version* file. You can modify this file using the `pyenv global` command. If the global version file is not present, pyenv assumes you want to use the *system* Python. (In other words, whatever version would run if pyenv weren't in your *PATH*.)\n\nIn other words, there are two ways to specify a python version to use:\n  - Change the version being used for the current session by running `pyenv shell \u003cversion\u003e`. Running `pyenv shell` or `pyenv version` would now show `\u003cversion\u003e` as output. For this session, until changed, this version will be used for running python scripts. We can run `pyenv shell --unset` to revert to the shell being originally used before any such commands were executed. *This choice has the higest precedence.*\n  - Create a *.python-version* file by running `pyenv local \u003cversion\u003e` in a project directory. Whenever scripts are run from this directory, or *any* subdirectories, the chosen version will always be used, considering no shell version has been configured for the session. One can set multiple versions in decreasing order of precedence by running `pyenv local \u003cversion-1\u003e \u003cversion-2\u003e ...`  in a directory. Again, running `pyenv local` or `pyenv version` would now show the active versions as output. To unset this file/config, run `pyenv local --unset`.\n\nTo uninstall a python version, we can either run `pyenv uninstall \u003cversion\u003e` or remove the entire *{version}/* directory in *.pyenv/versions/*.\n\nTo create virtual environments (our original concern!), we run the command\n```bash\npyenv virtualenv \u003cversion\u003e \u003cenv-name\u003e\n```\ni.e. we select a `\u003cversion\u003e` and specify the name `\u003cenv-name\u003e` of the virtual environment we want to create. We can omit `\u003cversion\u003e`: in that case, the version currently set will be used to create the virtual environment, as determined by our configuration. The packages installed under this environment will be listed under the directory *.pyenv/versions/{version}/envs/{env-name}*. To activate this environment, we run\n```bash\npyenv activate \u003cenv-name\u003e\n```\nand `pyenv deactivate` to - well, deactivate the environment. To list created virtual environments, we run `pyenv virtualenvs`. It is possible to specify a virtual environment in a local *.python-version* file by running \n```bash\npyenv local \u003cenv-name\u003e\n```\nAs mentioned before, we can list multiple python versions, environments etc. separated by spaces.\n\nTo remove an environment altogether, we can run\n```bash\npyenv virtualenv-delete \u003cenv-name\u003e\n```\nor just delete the *{env-name}* directory in *.pyenv/versions/{version}/envs/*. \n\nAfter activating, we might want to install necessary packages. One could do this using a *requirements* text file which lists specific versions of packages (perhaps a natural use-case in virtual environments), passed to `pip`:\n```bash\npip install -r requirements.txt\n```\nIt could be helpful to use a `--no-cache-dir` option if `pip` uses cached versions which do not match the required version.[^cache]\n\n### Installing ipython kernel\n\nFinally, we could install an **ipython kernel** for a virtual environment, if we use **jupyter notebook** installed for the *system* version. Installing multiple jupyter instances may in general not make sense (?). So we run\n```bash\npyenv activate \u003cenv-name\u003e\npip install ipykernel ipython_genutils\n```\n**Note:** Depending upon the project and/or the python version, a specific version of ipykernel might be required. By installing **ipython_genutils** for the environment we can get away without installing **ipython** itself, since it will be installed for the *system* version.\n\nAfter the installation, we may run\n```bash\npython -m ipykernel install --user --name=\u003cenv-kernel-name\u003e\n```\nwhere we type in a name for this kernel. It need not be identical to `\u003cenv-name\u003e`. Now when we fire Jupyter Lab/notebook, this kernel should be available. We wouldn't need to activate the virtual environment for this purpose.\n\n\n\n\n\n\n\n\n[//]: # (Footnotes, if any)\n\n[^sizeissue]: Of course, one can ask here if this defeats the purpose of *not* installing **conda** - but it is probably not necessary to install all of these. It is *suggested* by the devs - the question of potential failure would probably need to be answered on a case-by-case basis. In any case, this step can probably be optimized. *TO BE INVESTIGATED*\n\n[^cache]: This may likely happen when the unlisted dependencies of the packages listed are installed from cache. However, using `--no-cache-dir` might significantly increase install times. Some details [here][pipnocache].\n\n\n\n\n\n[//]: # (Links, if any)\n\n[1]: \u003chttps://docs.python.org/3/library/venv.html\u003e\n[2]: \u003chttps://docs.conda.io/en/latest/miniconda.html\u003e\n[3]: \u003chttps://github.com/pyenv/pyenv\u003e\n[pyvnv]: \u003chttps://github.com/pyenv/pyenv-virtualenv\u003e\n[pyvnv-method]: \u003chttps://github.com/pyenv/pyenv-virtualenv#virtualenv-and-venv\u003e\n[buildenv]: \u003chttps://github.com/pyenv/pyenv/wiki#suggested-build-environment\u003e\n[shimswork]: \u003chttps://github.com/pyenv/pyenv#how-it-works\u003e\n[setup]: \u003chttps://github.com/pyenv/pyenv#basic-github-checkout\u003e\n[pipnocache]: \u003chttps://stackoverflow.com/questions/9510474/pip-uses-incorrect-cached-package-version-instead-of-the-user-specified-version/61762308#61762308\u003e","lastmodified":"2023-05-05T06:31:15.943194994Z","tags":["python","pyenv"]},"/notes/2022-07-31-tensorflow-cuda-wsl":{"title":"Installing Tensorflow on WSL with CUDA support","content":"[//]: # (The body)\n\nGetting **`tensorflow`** to work properly on WSL with GPU support can be a little difficult. One needs to use the right dependencies for the a particular version of tensorflow.[^venv] The dependencies are listed [here][pipinstall] for the latest version. For older versions, it is listed [here instead][depends].\n\nMy hardware configuration looks like this:\n```text\nCPU: AMD Ryzen 5800H (8, 16)\nGPU: NVIDIA GeForce RTX 3050Ti (Laptop)\nRAM: 16 GB (8 GB allowed on WSL2)\n```\nSoftware:\n```text\nUbuntu 22.04 LTS on WSL2\nNVIDIA Graphics Driver (Game-ready) 516.59\nCUDA toolkit 11.2 (11.7 supported)\ncuDNN 8.1.1\nPython 3.10.4\npip 22.2.1\ntensorflow 2.9.1\n```\nMost of this is inspired from [this guide][wslguide1]. However, parts of it didn't work for me and I had to tweak.\n\nWe start with installing the cuda toolkit. In our case, we have to choose version 11.2 (the latest is 11.7), so we must dive into the NVIDIA [archives][cudatk-arxv] and choose the right version. Then we select **Linux -\u003e x86_64 -\u003e WSL-Ubuntu -\u003e 2.0 -\u003e deb (local)**. I use the local **deb** installer, however, this is upto the user.\n\nAt this point, if any other versions of cuda are installed, we can uninstall them with\n```shell\nsudo apt --purge remove cuda\nsudo apt autoremove\n```\nThis will work only if cuda was installed with apt. Otherwise, one can follow the instructions in this [stackoverflow thread][cudatk-uninst]. To remove references to the cuda repo (since the reference might be version-specific), we have two options:\n  - Edit */etc/apt/sources.list* if it contains references to the NVIDIA cuda repo.\n  - Delete the key in */etc/apt/sources.list.d* that refers to the same.\nWe also delete the old apt key:\n```shell\nsudo apt-key del 7fa2af80\n```\n\nNow we can proceed with the installation.[^drivernote] (The following is from the installation instructions for v11.2.0. The full guide for installing CUDA on WSL is [here][cuda-wsl]):\n```shell\nwget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pin\nsudo mv cuda-wsl-ubuntu.pin /etc/apt/preferences.d/cuda-repository-pin-600\nwget https://developer.download.nvidia.com/compute/cuda/11.2.0/local_installers/cuda-repo-wsl-ubuntu-11-2-local_11.2.0-1_amd64.deb\nsudo dpkg -i cuda-repo-wsl-ubuntu-11-2-local_11.2.0-1_amd64.deb\nsudo apt-key add /var/cuda-repo-wsl-ubuntu-11-2-local/7fa2af80.pub\nsudo apt-get update\nsudo apt-get -y install cuda\n```\nGet a coffee - this might take time!\n\nMeanwhile, we can edit our rc file (.bashrc or .zshrc or whatever is relevant) and add the following lines:\n```shell\nexport PATH=\"/usr/local/cuda/bin:$PATH\"\nexport LD_LIBRARY_PATH=\"/usr/local/cuda/lib64:$LD_LIBRARY_PATH\"\n```\nFinally, we *source the rc file* to load the changes.\n\nNow we install cuDNN. Installation instructions are [here][cudnn-inst]. We just get the library files of cuDNN and copy them to the appropriate location. We do not use an installer.\nFirst, we install `zlib1g`, a compression library required by cuDNN (in my case, it was already installed):\n```shell\nsudo apt install zlib1g\n```\nNow we have to sign up for the NVIDIA Developer Program first. Once we're done and are signed in, we can proceed to downloading cuDNN. We go the [cuDNN archive][cudnn-arxv] and choose the appropriate version (v8.1.1 - the most recent version is listed [here instead][cudnn-down]). We choose the \"cuDNN Library for Linux (x86_64)\" option, which downloads a tar file. We move this tar file to our WSL distro (for quicker file ops) and extract this using\n```shell\ntar xvf \u003cfilename\u003e\n```\nwhere *\\\u003cfilename\\\u003e* should start with *cudnn-x.y-* where *x.y* is the cuda version.\n\nFrom the folder in which files were extracted, we copy these files like so:\n```shell\nsudo cp \u003cextracted-folder-name\u003e/include/cudnn*.h /usr/local/cuda/include \nsudo cp -P \u003cextracted-folder-name\u003e/lib/libcudnn* /usr/local/cuda/lib64 \n```\nand change the permissions of these files to allow all users to read them:\n```shell\nsudo chmod a+r /usr/local/cuda/include/cudnn*.h /usr/local/cuda/lib64/libcudnn*\n```\nFinally, we install tensorflow:\n```shell\npip install tensorflow\n```\nThis will also, likely, take time. After that, we're done with the installation!\n\nNow we can run this in a python shell to verify our \n```python\nimport tensorflow as tf\nprint(tf.config.list_physical_devices('GPU'))\n```\n\nIf this shows a non-empty list, tensorflow recognizes the gpu and the necessary libraries.[^numawarn] Typically, this output will look something like\n\n```python\n[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n```\n\n\n\n\n\n\n\n\n\n\n[//]: # (Footnotes, if any)\n\n[^venv]: This naturally calls for the use of a virtual environment specifically for development involving `tensorflow` but we will be skipping this adventure here. This is traditionally done with **conda** - as most of the guides recommend. However, [issues][tf-conda] have been reported on WSL using this method. We can use a typical virtual environment (`virtualenv`) instead.\n[^drivernote]: The display driver must be installed on **Windows**. No separate installation of a graphics drivers is required on WSL. Standard cuda toolkits for Linux include the driver - so we cannot choose those versions.\n[^numawarn]: If a warning is given by tensorflow about `Your kernel may have been built without NUMA support.`: this is probably nothing to worry about, as discussed in [this thread][numaissue].\n\n\n\n\n\n[//]: # (Links, if any)\n\n[pipinstall]: \u003chttps://www.tensorflow.org/install/pip\u003e\n[depends]: \u003chttps://www.tensorflow.org/install/source#tested_build_configurations\u003e\n[wslguide1]: \u003chttps://medium.com/@xizengmao/install-tensorflow-with-gpu-acceleration-simultaneously-for-windows-and-wsl-linux-2-10da088d5e4f\u003e\n[cudatk-arxv]: \u003chttps://developer.nvidia.com/cuda-toolkit-archive\u003e\n[cudatk-uninst]: \u003chttps://stackoverflow.com/questions/56431461/how-to-remove-cuda-completely-from-ubuntu\u003e\n[cudnn-inst]: \u003chttps://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html\u003e\n[cudnn-arxv]: \u003chttps://developer.nvidia.com/rdp/cudnn-archive\u003e\n[cudnn-down]: \u003chttps://developer.nvidia.com/rdp/cudnn-download\u003e\n[cuda-wsl]: \u003chttps://docs.nvidia.com/cuda/wsl-user-guide/index.html\u003e\n[numaissue]: \u003chttps://forums.developer.nvidia.com/t/numa-error-running-tensorflow-on-jetson-tx2/56119/4\u003e\n[tf-conda]: \u003chttps://stackoverflow.com/a/71058493/12983399\u003e","lastmodified":"2023-05-05T06:31:15.943194994Z","tags":["tensorflow","cuda","wsl","gpu"]},"/notes/2022-11-03-ssh-keychain":{"title":"Ask SSH key passphrase on demand","content":"[//]: # (The body)\n\nOur core focus here is to be able to ssh without typing passphrases a million times, but not be forced to enter passphrases on login, if they're never required for the session. The job of an `ssh-agent` is to remember our passphrases. For a discussion on the merits and demerits of different approaches, [this stackoverflow answer][stof-ssh-types] is insightful.\n\n## Start `ssh-agent` on login\n\nThere are many ways to start an `ssh-agent` on login. Here we explore two ways: one using a script and the other using small tool named `keychain`.\n\n### Using a script\n\nWe can start the `ssh-agent` on login by adding a few lines to our profile files. This follows a modified version of [this stackoverflow answer][stof-autoagent]. This could be added to the */etc/profile.d* folder as a script, but it seems like it [doesn't work for zsh][asku-zshprof]. So we add this to our *~/.zprofile*. \n\n```shell {title=\"~/.zprofile\"}\n# Start the SSH agent only if not running\n[[ -z $(ps | grep ssh-agent) ]] \u0026\u0026 echo $(ssh-agent) \u003e /tmp/ssh-agent-data.sh\n\n# Identify the running SSH agent\n[[ -z $SSH_AGENT_PID ]] \u0026\u0026 source /tmp/ssh-agent-data.sh \u003e /dev/null\n\n# Kill ssh-agent on logout\ntrap 'test -z $SSH_AGENT_PID \u0026\u0026 eval $(/usr/bin/ssh-agent -k)' 0\n```\nHere we just check if the agent is already running - if not, we run it. Finally, when logging out, we kill the `ssh-agent`.\n\n### Using `keychain`\n\nThe advantage of using [keychain][keychain-page] is it handles all the complications of adding keys and persisting them through logins if required. We will use it in a very limited manner, to only start `ssh-agent` reliably and persisting through logins if so desired.\n\nWe will first install `keychain`:\n```shell\nsudo apt-get install keychain\n```\nNow we will modify *~/.profile*, *~/.bash_profile* or *~/.zprofile* (whichever is appropriate) and add the following:\n```shell {title=\"~/.zprofile\"}\neval $(keychain -q --clear --eval --agents ssh)\n```\nThis will start `keychain` on login and it will handle the addition of `ssh-agent`. We wouldn't have to worry about spawning multiple agents at the same time. `keychain` is designed to persist the ssh keys even after logout, until a reboot. However, we have used the `--clear` option, which clears ssh keys on logout.[^kc-clear] This is safer than the standard behaviour of keychain. The other options:\n- `-q` suppresses info output of `keychain`.\n- `--eval` prints lines to be evaluated on **stdout** (which is why we put `eval` in front)\n- `--agents` specifies the kind of agent to start. \n\n## Adding keys on-the-fly\n\nOne could also provide names of keys to the script or `keychain`, to be automatically added on login. However, we wouldn't exploit this behaviour. We would instead use configure the `ssh-agent` to [automatically add keys][ssh-autokeys] to it.[^ssh-autokeys] To do so, we edit the configuration file *~/.ssh/config* (and create it if it does not exist):\n``` {title=\"~/.ssh/config\"}\nHost *\n\tIdentityFile /path/to/file\n\tAddKeysToAgent yes\n```\nHere we add this for all hosts. It's definitely possible to do [advanced configurations][ssh-config] if required. One probably does not need to provide the `IdentityFile` if the name of the private key file is one of the \"standard\" names[^std-id-files]. Whether the ssh key is being picked up can be seen in the `ssh` output when used:\n```shell\nssh -vvvv git@github.com\n```\nThe `AddKeysToAgent` option is key here. *If* an `ssh-agent` is running (which we've ensured in the previous step), it adds a key to the agent when one is used. The [ssh changelog][ssh-v7_2] explains:\n\n\u003e\\* ssh(1): Add an AddKeysToAgent client option which can be set to\n   'yes', 'no', 'ask', or 'confirm', and defaults to 'no'.  When\n   enabled, a private key that is used during authentication will be\n   added to ssh-agent if it is running (with confirmation enabled if\n   set to 'confirm').\n\nMore details can be found in the [ssh configuration page][ssh-conf-addkeys]. \n\nWe're essentially done here. Now passphrases will be asked when required and once given, will be remembered by the `ssh-agent` for the session. \n\n\n\n\n\n\n\n\n[//]: # (Footnotes, if any)\n\n[^kc-clear]: But lets cron jobs still use ssh keys after logout. \n[^ssh-autokeys]: This is a *recent* (!) addition (2016, SSH v7.2).\n[^std-id-files]: These files are named after the protocol, for instance *id_rsa* or *id_ed25519*. It is possible to override this behaviour by adding the option `IdentitiesOnly yes` to the config file.\n\n\n\n\n\n[//]: # (Links, if any)\n\n[stof-ssh-types]: \u003chttps://unix.stackexchange.com/a/90869/428839\u003e\n[keychain-page]: \u003chttps://www.funtoo.org/Funtoo:Keychain\u003e\n[ssh-autokeys]: \u003chttps://unix.stackexchange.com/a/319964/428839\u003e\n[ssh-config]: \u003chttps://linuxize.com/post/using-the-ssh-config-file/\u003e\n[stof-autoagent]: \u003chttps://stackoverflow.com/a/24347344/12983399\u003e\n[asku-zshprof]: \u003chttps://askubuntu.com/a/476435/1049026\u003e\n[ssh-v7_2]: \u003chttps://www.openssh.com/txt/release-7.2\u003e\n[ssh-conf-addkeys]: \u003chttps://man.openbsd.org/ssh_config#AddKeysToAgent\u003e","lastmodified":"2023-05-05T06:31:15.943194994Z","tags":["ssh","keychain","wsl"]},"/notes/2022-11-10-vscode-latex":{"title":"2022-11-10-vscode-latex","content":"[//]: # (The body)\n\nWhen it comes to installing software, my primary goal is optimization between saving storage space and having a convenient (enough) workflow. Installing an entire **LaTeX** distribution can consume \u003e7 GB worth of storage space. Even though small TeX distributions may not be very useful, there is still space for optimisation. \n\nIn this workflow, we first install **TeXLive** on WSL (Ubuntu 22.04). There are many ways to do this, but we stick to the one advised on [the official website][tug-offcl] for Unix-like systems:\nFirst, we get the installer:\n```shell\nwget https://mirror.ctan.org/systems/texlive/tlnet/install-tl-unx.tar.gz \n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[//]: # (Footnotes, if any)\n\n[^fn]: Footnote\n\n\n\n\n\n[//]: # (Links, if any)\n\n[tug-offcl]: https://tug.org/texlive/quickinstall.html","lastmodified":"2023-05-05T06:31:15.943194994Z","tags":["vscode","LaTeX"]},"/notes/2023-04-26-new-user-linux":{"title":"Different aspects of creating a new user in Linux","content":"[//]: # (The body)\n\nThis is only a template.\n\n\n\n\n\n\n\n[//]: # (Footnotes, if any)\n\n[^fn]: Footnote\n\n\n\n\n\n[//]: # (Links, if any)\n\n[1]: \u003cgoogle.com\u003e","lastmodified":"2023-05-05T06:31:15.943194994Z","tags":["linux","password","user"]}}